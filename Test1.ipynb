{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Test2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\R_CORDEI\\Downloads\\DSD_Ass2\\Assignment2_DSD_Parallel_Programming\\Test1.ipynb Cell 1\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/R_CORDEI/Downloads/DSD_Ass2/Assignment2_DSD_Parallel_Programming/Test1.ipynb#W0sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/R_CORDEI/Downloads/DSD_Ass2/Assignment2_DSD_Parallel_Programming/Test1.ipynb#W0sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmath\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/R_CORDEI/Downloads/DSD_Ass2/Assignment2_DSD_Parallel_Programming/Test1.ipynb#W0sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m\"\u001b[39m\u001b[39mTest2\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/R_CORDEI/Downloads/DSD_Ass2/Assignment2_DSD_Parallel_Programming/Test1.ipynb#W0sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m prefix \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mS\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mP\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/R_CORDEI/Downloads/DSD_Ass2/Assignment2_DSD_Parallel_Programming/Test1.ipynb#W0sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39morigin_with_S_P\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39miloc[:,\u001b[39m2\u001b[39m]\u001b[39m.\u001b[39mstr\u001b[39m.\u001b[39mstartswith(\u001b[39mtuple\u001b[39m(prefix))\n",
      "File \u001b[1;32mc:\\Users\\R_CORDEI\\AppData\\Local\\anaconda3\\envs\\Python_New\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\R_CORDEI\\AppData\\Local\\anaconda3\\envs\\Python_New\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    610\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 611\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    613\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    614\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\R_CORDEI\\AppData\\Local\\anaconda3\\envs\\Python_New\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   1447\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1448\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_engine(f, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine)\n",
      "File \u001b[1;32mc:\\Users\\R_CORDEI\\AppData\\Local\\anaconda3\\envs\\Python_New\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1703\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[0;32m   1704\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1705\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[0;32m   1706\u001b[0m     f,\n\u001b[0;32m   1707\u001b[0m     mode,\n\u001b[0;32m   1708\u001b[0m     encoding\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m),\n\u001b[0;32m   1709\u001b[0m     compression\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mcompression\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m),\n\u001b[0;32m   1710\u001b[0m     memory_map\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mmemory_map\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m),\n\u001b[0;32m   1711\u001b[0m     is_text\u001b[39m=\u001b[39mis_text,\n\u001b[0;32m   1712\u001b[0m     errors\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mencoding_errors\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mstrict\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m   1713\u001b[0m     storage_options\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mstorage_options\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m),\n\u001b[0;32m   1714\u001b[0m )\n\u001b[0;32m   1715\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1716\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\R_CORDEI\\AppData\\Local\\anaconda3\\envs\\Python_New\\Lib\\site-packages\\pandas\\io\\common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    859\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    862\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 863\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(\n\u001b[0;32m    864\u001b[0m             handle,\n\u001b[0;32m    865\u001b[0m             ioargs\u001b[39m.\u001b[39mmode,\n\u001b[0;32m    866\u001b[0m             encoding\u001b[39m=\u001b[39mioargs\u001b[39m.\u001b[39mencoding,\n\u001b[0;32m    867\u001b[0m             errors\u001b[39m=\u001b[39merrors,\n\u001b[0;32m    868\u001b[0m             newline\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    869\u001b[0m         )\n\u001b[0;32m    870\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    872\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Test2'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "df = pd.read_csv(\"Test2\")\n",
    "prefix = ['S','P']\n",
    " \n",
    "df['origin_with_S_P'] = df.iloc[:,2].str.startswith(tuple(prefix))\n",
    "\n",
    "#total_s_or_p = len(df['origin_with_S_P'])\n",
    "total_s_or_p = df['origin_with_S_P'].tolist().count(True)\n",
    "#print(df['origin_with_S_P'])\n",
    "print(f\"total: {total_s_or_p}\")\n",
    "# #matched_rows =  df.iloc[:,2].str.startswith(tuple(prefix))\n",
    "# df.iloc[:, 2].apply(lambda x: x.str.startswith(tuple(prefix)))\n",
    "# #print(matched_rows.tolist())\n",
    "# def is_true(value):\n",
    "#     if value:\n",
    "#         return True\n",
    "#     else:\n",
    "#         return False\n",
    "\n",
    "#print(df['origin_with_S_P'].value_counts().apply(lambda x: )\n",
    "      \n",
    "#print(df.groupby(\"Airline\").agg({\"origin_with_S_P\": lambda x: list(x)}))\n",
    "\n",
    "      \n",
    "#print(df.groupby(\"Airline\").agg({\"origin_with_S_P\": lambda x: list(x)}).count(True))\n",
    "#df.loc[:, matched_rows].head() \n",
    "\n",
    "# result = (\n",
    "#   df\n",
    "#   .groupby(['Airline'])\n",
    "#   .apply(lambda x: pd.Series({\n",
    "#      # 'nb_flights_with_S_P': x['origin_with_S_P'].sum() / len(x)\n",
    "#     'S_P_Percentage':  (x['origin_with_S_P'].sum() / total_s_or_p) * 100\n",
    "\n",
    "#   }))\n",
    "#   .apply(lambda x : pd.Series({\n",
    "#     'S_P_True_Value':  x['origin_with_S_P'].sum()\n",
    "#   }))\n",
    "#   .reset_index()\n",
    "# )\n",
    "result = (\n",
    "  df\n",
    "  .groupby(['Airline'])\n",
    "  .apply(lambda x : pd.Series({\n",
    "    'S_P_Percentage':  (x['origin_with_S_P'].sum() / total_s_or_p) * 100\n",
    "  }))\n",
    "  .reset_index()\n",
    ")\n",
    "print(result)\n",
    "\n",
    "result.max(axis = 0 ).values[0] ## returns Airline Name\n",
    "\n",
    "\n",
    "\n",
    "#result['nb_flights_with_S_P'].max(axis=0)\n",
    "# max_airline = result['nb_flights_with_S_P'].idxmax()\n",
    "\n",
    "# print(max_airline)\n",
    "\n",
    "#print(df.groupby(\"Airline\").transform({\"origin_with_S_P\": lambda x: x/x.sum()*100}))\n",
    "\n",
    "\n",
    "#print(df[['Airline','Origin','origin_with_S_P']])\n",
    "#print(pd.DataFrame({'Airline': [True]}).bool())\n",
    "#print(df[df[df['origin_with_S_P']].index])\n",
    "#df = df.groupby('Airline')['origin_with_S_P'].apply(list)\n",
    "#print(df)\n",
    "\n",
    "# matched_rows=df.iloc[:,2].str.startswith(tuple(prefix))\n",
    "# print(\"df\")\n",
    "# print(pd.DataFrame(matched_rows))\n",
    "# print(matched_rows.tolist())\n",
    "\n",
    "# df.loc[:, ['origin_with_S_P']].head() \n",
    "\n",
    "\n",
    "\n",
    "df2 = pd.read_csv(\"Test2.csv\")\n",
    "\n",
    "\n",
    "\n",
    "df2['origin_with_S_P'] = df2.iloc[:,2].str.startswith(tuple(prefix))\n",
    "\n",
    "\n",
    "result2 = (\n",
    "  df2\n",
    "  .groupby(['Airline'])\n",
    "  .apply(lambda x : pd.Series({\n",
    "    'S_P_True_Value':  x['origin_with_S_P'].sum()\n",
    "  }))\n",
    "  .reset_index()\n",
    ")\n",
    "print(result2)\n",
    "\n",
    "# final_result2 = result2.to_dict()\n",
    "\n",
    "\n",
    "\n",
    "#df.add(df2, fill_value=0)\n",
    "\n",
    "# for key,value in final_result2:\n",
    "#   if key in result['Airline']:\n",
    "#     final_result[key] = final_result.get(key) + value\n",
    "#   else:\n",
    "#     final_result[key]= value\n",
    "\n",
    "\n",
    "# print(final_result)\n",
    "    \n",
    "# df_add = result.add(result2,fill_value=0)\n",
    "\n",
    "# print(df_add)\n",
    "\n",
    "\n",
    "# result = result.set_index(\"Airline\")\n",
    "# result2 = result2.set_index(\"Airline\")\n",
    "\n",
    "# mask = result.index.isin(result.index)\n",
    "\n",
    "# df2['S_P_True_Value'] += df.loc[mask,'S_P_True_Value']\n",
    "\n",
    "\n",
    "#df_merge = pd.merge(result, result2 , on=\"Airline\")\n",
    "\n",
    "#df_merge.head()\n",
    "final= pd.DataFrame()\n",
    "if(not final.empty):\n",
    "  r=pd.merge(result, final, how=\"outer\")\n",
    "print(r)\n",
    "\n",
    "df_final = r.groupby(\"Airline\").agg({'S_P_True_Value': 'sum'}).apply( lambda x : pd.Series({\n",
    "    'S_P_True_Value':  x['origin_with_S_P'].sum() / 2\n",
    "  }))\n",
    "\n",
    "print(df_final)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_final.max(axis = 0 ).values[0] ## returns Airline Name\n",
    "\n",
    "# for key, value in result.to_dict().items():\n",
    "#     if key in result:\n",
    "#         result[key] = result.get(key) + value\n",
    "#     else:\n",
    "#         result[key] = value\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "to assemble mappings requires at least that [year, month, day] be specified: [day] is missing",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\R_CORDEI\\Downloads\\DSD_Ass2\\Assignment2_DSD_Parallel_Programming\\Test1.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/R_CORDEI/Downloads/DSD_Ass2/Assignment2_DSD_Parallel_Programming/Test1.ipynb#W4sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m df\u001b[39m=\u001b[39mpd\u001b[39m.\u001b[39mread_csv(\u001b[39m\"\u001b[39m\u001b[39mTest2.csv\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/R_CORDEI/Downloads/DSD_Ass2/Assignment2_DSD_Parallel_Programming/Test1.ipynb#W4sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m#df['formatted_depTime']=pd.to_datetime(df['DepTime'], format='%H%M').dt.strftime('%H:%M')\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/R_CORDEI/Downloads/DSD_Ass2/Assignment2_DSD_Parallel_Programming/Test1.ipynb#W4sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/R_CORDEI/Downloads/DSD_Ass2/Assignment2_DSD_Parallel_Programming/Test1.ipynb#W4sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# df2 = df.loc[df['Origin']=='ATL']\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/R_CORDEI/Downloads/DSD_Ass2/Assignment2_DSD_Parallel_Programming/Test1.ipynb#W4sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/R_CORDEI/Downloads/DSD_Ass2/Assignment2_DSD_Parallel_Programming/Test1.ipynb#W4sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m#df = df.loc[(pd.to_datetime(df['FlightDate']).dt.month == 11) & (df['Origin'] =='ATL')]\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/R_CORDEI/Downloads/DSD_Ass2/Assignment2_DSD_Parallel_Programming/Test1.ipynb#W4sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mloc[(pd\u001b[39m.\u001b[39mto_datetime(df\u001b[39m.\u001b[39miloc[:\u001b[39m1\u001b[39m])\u001b[39m.\u001b[39mdt\u001b[39m.\u001b[39mmonth \u001b[39m==\u001b[39m \u001b[39m11\u001b[39m) \u001b[39m&\u001b[39m (df\u001b[39m.\u001b[39miloc[:\u001b[39m2\u001b[39m] \u001b[39m==\u001b[39m\u001b[39m'\u001b[39m\u001b[39mATL\u001b[39m\u001b[39m'\u001b[39m)]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/R_CORDEI/Downloads/DSD_Ass2/Assignment2_DSD_Parallel_Programming/Test1.ipynb#W4sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39m#print(df)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/R_CORDEI/Downloads/DSD_Ass2/Assignment2_DSD_Parallel_Programming/Test1.ipynb#W4sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/R_CORDEI/Downloads/DSD_Ass2/Assignment2_DSD_Parallel_Programming/Test1.ipynb#W4sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/R_CORDEI/Downloads/DSD_Ass2/Assignment2_DSD_Parallel_Programming/Test1.ipynb#W4sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39m#     formatted_time = f\"{hours.zfill(2)}:{minutes.zfill(2)}\"\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/R_CORDEI/Downloads/DSD_Ass2/Assignment2_DSD_Parallel_Programming/Test1.ipynb#W4sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39m#     return formatted_time\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/R_CORDEI/Downloads/DSD_Ass2/Assignment2_DSD_Parallel_Programming/Test1.ipynb#W4sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39madd_trailing_zeroes\u001b[39m(number):\n",
      "File \u001b[1;32mc:\\Users\\R_CORDEI\\AppData\\Local\\anaconda3\\envs\\Python_New\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1115\u001b[0m, in \u001b[0;36mto_datetime\u001b[1;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[0;32m   1113\u001b[0m         result \u001b[39m=\u001b[39m arg\u001b[39m.\u001b[39m_constructor(values, index\u001b[39m=\u001b[39marg\u001b[39m.\u001b[39mindex, name\u001b[39m=\u001b[39marg\u001b[39m.\u001b[39mname)\n\u001b[0;32m   1114\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(arg, (ABCDataFrame, abc\u001b[39m.\u001b[39mMutableMapping)):\n\u001b[1;32m-> 1115\u001b[0m     result \u001b[39m=\u001b[39m _assemble_from_unit_mappings(arg, errors, utc)\n\u001b[0;32m   1116\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(arg, Index):\n\u001b[0;32m   1117\u001b[0m     cache_array \u001b[39m=\u001b[39m _maybe_cache(arg, \u001b[39mformat\u001b[39m, cache, convert_listlike)\n",
      "File \u001b[1;32mc:\\Users\\R_CORDEI\\AppData\\Local\\anaconda3\\envs\\Python_New\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1231\u001b[0m, in \u001b[0;36m_assemble_from_unit_mappings\u001b[1;34m(arg, errors, utc)\u001b[0m\n\u001b[0;32m   1229\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(req):\n\u001b[0;32m   1230\u001b[0m     _required \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(req)\n\u001b[1;32m-> 1231\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1232\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mto assemble mappings requires at least that \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1233\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[year, month, day] be specified: [\u001b[39m\u001b[39m{\u001b[39;00m_required\u001b[39m}\u001b[39;00m\u001b[39m] is missing\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1234\u001b[0m     )\n\u001b[0;32m   1236\u001b[0m \u001b[39m# keys we don't recognize\u001b[39;00m\n\u001b[0;32m   1237\u001b[0m excess \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39m(\u001b[39mset\u001b[39m(unit_rev\u001b[39m.\u001b[39mkeys()) \u001b[39m-\u001b[39m \u001b[39mset\u001b[39m(_unit_map\u001b[39m.\u001b[39mvalues()))\n",
      "\u001b[1;31mValueError\u001b[0m: to assemble mappings requires at least that [year, month, day] be specified: [day] is missing"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "#df = pd.read_csv(\"implementation/Combined_Flights_2021.csv\")\n",
    "\n",
    "df=pd.read_csv(\"Test2.csv\")\n",
    "\n",
    "\n",
    "#df['formatted_depTime']=pd.to_datetime(df['DepTime'], format='%H%M').dt.strftime('%H:%M')\n",
    "\n",
    "# df2 = df.loc[df['Origin']=='ATL']\n",
    "\n",
    "# print(df2)\n",
    "\n",
    "#df = df.loc[(pd.to_datetime(df['FlightDate']).dt.month == 11) & (df['Origin'] =='ATL')]\n",
    "\n",
    "df = df.loc[(pd.to_datetime(df.iloc[:1]).dt.month == 11) & (df.iloc[:2] =='ATL')]\n",
    "\n",
    "#print(df)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def add_trailing_zeros(time_str):\n",
    "#     hours, minutes = time_str.split(':')\n",
    "#     formatted_time = f\"{hours.zfill(2)}:{minutes.zfill(2)}\"\n",
    "#     return formatted_time\n",
    "\n",
    "\n",
    "def add_trailing_zeroes(number):\n",
    "   \n",
    "    if (not math.isnan(number)):\n",
    "        print(f\"if{number}\")\n",
    "        return f\"{int(number):0<{4}}\"\n",
    "    # else:\n",
    "    #     print(number)\n",
    "    #     return number\n",
    "\n",
    "def get_hour(number):\n",
    "   \n",
    "    if (not math.isnan(number)):\n",
    "        if(len(str(number))) == 4:\n",
    "            \n",
    "            return (str(number)[:2])\n",
    "        else:\n",
    "            return (str(number)[:1])\n",
    "    # else:\n",
    "    #     print(number)\n",
    "    #     return number\n",
    "    \n",
    "    \n",
    "\n",
    "# df['DepTime'] = df['DepTime'].apply(add_trailing_zeroes)\n",
    "\n",
    "# print(df['DepTime'])\n",
    "\n",
    "df['Hour']= df['CRSDepTime'].apply(get_hour)\n",
    "\n",
    "#print(df['Hour'])\n",
    "\n",
    "\n",
    "hourly_avg_count  = df['Hour'].value_counts()\n",
    "\n",
    "print(hourly_avg_count.sort_values())\n",
    "\n",
    "busiest_hour = hourly_avg_count.idxmax()\n",
    "\n",
    "print(busiest_hour)\n",
    "\n",
    "\n",
    "# hour\n",
    "# df['Hour'] =  pd.to_datetime(df['DepTime'],infer_datetime_format=True,format='%H%M').dt.strftime('%H')\n",
    "\n",
    "# print(df['Hour'])\n",
    "\n",
    "#print(add_leading_zeroes(mel))\n",
    "#df.resample('Hour')['value'].mean().reset_index(name='mean_val')\n",
    "\n",
    "# result = (\n",
    "# df2.groupby('hour').apply(lambda x : pd.Series({\n",
    "#     'hourly_avg':  x['Hour'].mean()\n",
    "#     #'S_P_Percentage':  x['origin_with_S_P'].sum()\n",
    "\n",
    "# }))\n",
    "# .reset_index()\n",
    "# )\n",
    "\n",
    "#hourly_count = df['Hour'].value_counts()\n",
    "\n",
    "#print(hourly_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df-ATL\n",
      "  FlightDate Airline Origin Dest Cancelled Diverted  CRSDepTime  DepTime  \\\n",
      "0        NaN     NaN    ATL  NaN       NaN      NaN         NaN      NaN   \n",
      "1        NaN     NaN    ATL  NaN       NaN      NaN         NaN      NaN   \n",
      "2        NaN     NaN    ATL  NaN       NaN      NaN         NaN      NaN   \n",
      "3        NaN     NaN    NaN  NaN       NaN      NaN         NaN      NaN   \n",
      "4        NaN     NaN    NaN  NaN       NaN      NaN         NaN      NaN   \n",
      "\n",
      "   DepDelayMinutes  DepDelay  ...  WheelsOff  WheelsOn  TaxiIn  CRSArrTime  \\\n",
      "0              NaN       NaN  ...        NaN       NaN     NaN         NaN   \n",
      "1              NaN       NaN  ...        NaN       NaN     NaN         NaN   \n",
      "2              NaN       NaN  ...        NaN       NaN     NaN         NaN   \n",
      "3              NaN       NaN  ...        NaN       NaN     NaN         NaN   \n",
      "4              NaN       NaN  ...        NaN       NaN     NaN         NaN   \n",
      "\n",
      "   ArrDelay  ArrDel15  ArrivalDelayGroups  ArrTimeBlk  DistanceGroup  \\\n",
      "0       NaN       NaN                 NaN         NaN            NaN   \n",
      "1       NaN       NaN                 NaN         NaN            NaN   \n",
      "2       NaN       NaN                 NaN         NaN            NaN   \n",
      "3       NaN       NaN                 NaN         NaN            NaN   \n",
      "4       NaN       NaN                 NaN         NaN            NaN   \n",
      "\n",
      "   DivAirportLandings  \n",
      "0                 NaN  \n",
      "1                 NaN  \n",
      "2                 NaN  \n",
      "3                 NaN  \n",
      "4                 NaN  \n",
      "\n",
      "[5 rows x 61 columns]\n"
     ]
    }
   ],
   "source": [
    "from numpy import isin\n",
    "import pandas as pd\n",
    "import math\n",
    "df = pd.read_csv(\"Test2.csv\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_ATL = df[pd.to_datetime(df.iloc[:,0]).dt.month == 11 ]\n",
    "\n",
    "# print(\"df-ATL1\")\n",
    "# print(df_ATL)\n",
    "\n",
    "\n",
    "df_ATL = df_ATL[df_ATL.iloc[:3] =='ATL']\n",
    "\n",
    "print(\"df-ATL\")\n",
    "print(df_ATL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on_time\n",
      "0           0.0\n",
      "1           0.0\n",
      "2           0.0\n",
      "3           0.0\n",
      "4           0.0\n",
      "           ... \n",
      "6311866     0.0\n",
      "6311867     0.0\n",
      "6311868     0.0\n",
      "6311869     0.0\n",
      "6311870    21.0\n",
      "Name: on_time, Length: 6311871, dtype: float64\n",
      "on_time\n",
      "0.0       4166398\n",
      "1.0        104851\n",
      "2.0         97803\n",
      "3.0         90752\n",
      "4.0         83975\n",
      "           ...   \n",
      "1765.0          1\n",
      "1166.0          1\n",
      "1471.0          1\n",
      "1452.0          1\n",
      "1512.0          1\n",
      "Name: count, Length: 1601, dtype: int64\n",
      "4166398\n",
      "                                      Airline  onTime_Percentage\n",
      "0                 Air Wisconsin Airlines Corp           1.264090\n",
      "1                        Alaska Airlines Inc.           2.821838\n",
      "2                               Allegiant Air           1.381433\n",
      "3                      American Airlines Inc.          11.881558\n",
      "4                 Capital Cargo International           1.717215\n",
      "5                                 Comair Inc.           3.719880\n",
      "6   Commutair Aka Champlain Enterprises, Inc.           1.038931\n",
      "7                        Delta Air Lines Inc.          13.225693\n",
      "8                        Empire Airlines Inc.           0.002136\n",
      "9                           Endeavor Air Inc.           5.213760\n",
      "10                                  Envoy Air           4.151476\n",
      "11                     Frontier Airlines Inc.           2.051556\n",
      "12   GoJet Airlines, LLC d/b/a United Express           0.930732\n",
      "13                     Hawaiian Airlines Inc.           1.015649\n",
      "14                                Horizon Air           1.782067\n",
      "15                            JetBlue Airways           2.788932\n",
      "16                         Mesa Airlines Inc.           2.421132\n",
      "17                          Republic Airlines           5.679966\n",
      "18                      SkyWest Airlines Inc.          12.312698\n",
      "19                     Southwest Airlines Co.          14.851438\n",
      "20                           Spirit Air Lines           2.775347\n",
      "21                      United Air Lines Inc.           6.972474\n"
     ]
    }
   ],
   "source": [
    "from numpy import isin\n",
    "import pandas as pd\n",
    "import math\n",
    "df = pd.read_csv(\"implementation\\Combined_Flights_2021.csv\")\n",
    "\n",
    "df['on_time'] = df.iloc[:,11]\n",
    "\n",
    "print(\"on_time\")\n",
    "\n",
    "print(df['on_time'])\n",
    "\n",
    "on_time = df['on_time'].tolist().count(0)\n",
    "\n",
    "\n",
    "check = df['on_time'].value_counts()\n",
    "\n",
    "print(check)\n",
    "\n",
    "print(on_time)\n",
    "\n",
    "result = (\n",
    "df.groupby(df.iloc[:,1]).apply(lambda x : pd.Series({\n",
    "    'onTime_Percentage':  (x['on_time'].eq(0).sum() / on_time ) * 100\n",
    "    #'S_P_Percentage':  x['origin_with_S_P'].sum()\n",
    "\n",
    "}))\n",
    ".reset_index()\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count\n",
      "1196680\n",
      "                                      Airline  arrive_early_per\n",
      "0                 Air Wisconsin Airlines Corp          0.831801\n",
      "1                        Alaska Airlines Inc.          2.019755\n",
      "2                               Allegiant Air          1.354748\n",
      "3                      American Airlines Inc.          7.460056\n",
      "4                 Capital Cargo International          1.224220\n",
      "5                                 Comair Inc.          2.381840\n",
      "6   Commutair Aka Champlain Enterprises, Inc.          0.762276\n",
      "7                        Delta Air Lines Inc.          9.453572\n",
      "8                        Empire Airlines Inc.          0.007103\n",
      "9                           Endeavor Air Inc.          4.058729\n",
      "10                                  Envoy Air          2.903199\n",
      "11                     Frontier Airlines Inc.          1.405806\n",
      "12   GoJet Airlines, LLC d/b/a United Express          0.574590\n",
      "13                     Hawaiian Airlines Inc.          0.543086\n",
      "14                                Horizon Air          1.471655\n",
      "15                            JetBlue Airways          1.638366\n",
      "16                         Mesa Airlines Inc.          1.950313\n",
      "17                          Republic Airlines          4.328977\n",
      "18                      SkyWest Airlines Inc.          9.459338\n",
      "19                     Southwest Airlines Co.         11.467727\n",
      "20                           Spirit Air Lines          1.986329\n",
      "21                      United Air Lines Inc.          4.544824\n"
     ]
    }
   ],
   "source": [
    "from numpy import isin\n",
    "import pandas as pd\n",
    "import math\n",
    "#df = pd.read_csv(\"Test2.csv\")\n",
    "\n",
    "df = pd.read_csv(\"implementation/Combined_Flights_2021.csv\")\n",
    "\n",
    "df['arr_delay_check'] = df.iloc[:,55] < 0\n",
    "\n",
    "#print(df['arr_delay_check'])\n",
    "\n",
    "#check = df['arr_delay_check'].value_counts()\n",
    "\n",
    "df['Quarter'] = pd.PeriodIndex(df['FlightDate'], freq='Q-DEC').strftime('Q%q')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df2Quarter = df.loc[df['Quarter'] == \"Q1\"]\n",
    "\n",
    "print(\"count\")\n",
    "\n",
    "print(df2Quarter['Quarter'].count())\n",
    "\n",
    "result = (\n",
    "df2Quarter.groupby(df2Quarter.iloc[:,1]).apply(lambda x : pd.Series({\n",
    "    'arrive_early_per':  ( x['arr_delay_check'].sum() / df2Quarter['Quarter'].count() ) * 100\n",
    "    #'S_P_Percentage':  x['origin_with_S_P'].sum()\n",
    "\n",
    "}))\n",
    ".reset_index()\n",
    ")\n",
    "\n",
    "print(result)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python_New",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
